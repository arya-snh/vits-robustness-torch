aa: None 
adv_training: trades
amp: false
attack: pgd
attack_boundaries:
- 0
- 1
attack_eps: 8
attack_lr: null
attack_norm: linf
attack_steps: 10
aug_splits: 0
batch_size: 64 
bce_loss: false
bce_target_thresh: null
bn_eps: null
bn_momentum: null
bn_tf: false
channels_last: false
checkpoint_hist: 10
clip_grad: null
clip_mode: norm
color_jitter: 0.0
cooldown_epochs: 2
crop_pct: null
cutmix: 0.0
cutmix_minmax: null
data_dir: ~/torch_data
dataset: torch/cifar10
decay_epochs: 100
decay_rate: 0.1
dist_bn: reduce
drop: 0.0
drop_block: null
drop_connect: null
drop_path: 0.05
epoch_repeats: 0.0
epochs: 20
eps_schedule: constant 
eps_schedule_period: 10
eval_metric: robust_top1
experiment: xcit-adv-finetuning-gpu
finetune: gs://robust-vits/xcit-adv-pretraining-3/best.pth.tar
finetuning_patch_size: 4
force_cpu: false
gp: null
hflip: 0.5
img_size: null
initial_checkpoint: ''
input_size:
  - 3
  - 32
  - 32
interpolation: ''
jsd_loss: false
keep_patch_embedding: true
local_rank: 0
log_interval: 50
log_wandb: false
lr: 2.0e-4
lr_cycle_decay: 0.5
lr_cycle_limit: 1
lr_cycle_mul: 1.0
lr_k_decay: 1.0
lr_noise: null
lr_noise_pct: 0.67
lr_noise_std: 1.0
mean:
  - 0.4914
  - 0.4822
  - 0.4465
min_lr: 5.0e-6
mixup: 0.0
mixup_mode: batch
mixup_off_epoch: 0
mixup_prob: 1.0
mixup_switch_prob: 0.5
model: xcit_small_12_p16_224
model_ema: false
model_ema_decay: 0.99996
momentum: 0.9
no_aug: false
no_normalize: true
no_resume_opt: false
normalize_model: true
num_classes: 10
opt: adamw 
opt_betas: null
opt_eps: 1.0e-08
output: gs://robust-vits/
patience_epochs: 10
pin_mem: false
pretrained: false
ratio:
- 0.95
- 1.05
recount: 1
recovery_interval: 0
remode: pixel
reprob: 0.20
resplit: false
resume: ''
save_images: false
scale:
- 0.8
- 1.2
sched: cosine
seed: 42
smoothing: 0.0
split_bn: false
start_epoch: null
std:
  - 0.2471
  - 0.2435
  - 0.2616
sync_bn: false
torchscript: false
trades_beta: 6.0
train_interpolation: bicubic
train_split: train
tta: 0
use_multi_epochs_loader: false
val_split: test
validation_batch_size: null
vflip: 0.0
warmup_epochs: 5
warmup_lr: 1.0e-06
weight_decay: 0.5
workers: 4
